/scratch/lustre/home/auma4493/TheNextModel/FinalEvaluation
args: Namespace(batch_size=32, dataset='glv2_t', model_checkpoint='/scratch/lustre/home/auma4493/TheNextModel/FinalTraining/checkpoints/disc/trained_model_13_13.pth', model_name='google/vit-large-patch16-224', model_type='disc', use_GeM=True)
Resolving data files:   0%|          | 0/138520 [00:00<?, ?it/s]Resolving data files:  15%|█▌        | 20883/138520 [00:00<00:00, 208803.32it/s]Resolving data files:  30%|███       | 41764/138520 [00:00<00:00, 196500.41it/s]Resolving data files:  44%|████▍     | 61463/138520 [00:00<00:00, 182080.15it/s]Resolving data files:  58%|█████▊    | 79777/138520 [00:00<00:00, 171386.35it/s]Resolving data files:  70%|███████   | 97012/138520 [00:00<00:00, 166700.91it/s]Resolving data files:  82%|████████▏ | 113730/138520 [00:00<00:00, 162859.91it/s]Resolving data files:  94%|█████████▍| 130038/138520 [00:00<00:00, 162033.36it/s]Resolving data files: 100%|██████████| 138520/138520 [00:00<00:00, 169144.41it/s]
Resolving data files:   0%|          | 0/1129 [00:00<?, ?it/s]Resolving data files: 100%|██████████| 1129/1129 [00:00<00:00, 20178.41it/s]
Resolving data files:   0%|          | 0/10000 [00:00<?, ?it/s]Resolving data files:  74%|███████▎  | 7371/10000 [00:00<00:00, 73344.60it/s]Resolving data files: 100%|██████████| 10000/10000 [00:00<00:00, 27060.10it/s]
Found cached dataset imagefolder (/scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/glv2-next-final-f1222a0f34855ac2/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:01,  1.83it/s] 67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s]100%|██████████| 3/3 [00:01<00:00,  1.90it/s]100%|██████████| 3/3 [00:01<00:00,  1.88it/s]
main dataset:  DatasetDict({
    train: Dataset({
        features: ['image'],
        num_rows: 138520
    })
    test: Dataset({
        features: ['image'],
        num_rows: 1129
    })
    validation: Dataset({
        features: ['image'],
        num_rows: 10000
    })
})
Resolving data files:   0%|          | 0/100000 [00:00<?, ?it/s]Resolving data files:  39%|███▉      | 39143/100000 [00:00<00:00, 391407.98it/s]Resolving data files:  78%|███████▊  | 78284/100000 [00:00<00:00, 364372.99it/s]Resolving data files: 100%|██████████| 100000/100000 [00:00<00:00, 137135.44it/s]
Resolving data files:   0%|          | 0/10000 [00:00<?, ?it/s]Resolving data files:  61%|██████    | 6097/10000 [00:00<00:00, 56459.79it/s]Resolving data files: 100%|██████████| 10000/10000 [00:00<00:00, 19224.12it/s]
Resolving data files:   0%|          | 0/100000 [00:00<?, ?it/s]Resolving data files:  31%|███       | 30542/100000 [00:00<00:00, 293520.07it/s]Resolving data files:  63%|██████▎   | 62806/100000 [00:00<00:00, 310361.08it/s]Resolving data files:  97%|█████████▋| 97078/100000 [00:00<00:00, 324996.61it/s]Resolving data files: 100%|██████████| 100000/100000 [00:00<00:00, 228343.83it/s]
Found cached dataset imagefolder (/scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/disc21-next-final-453d375012a0d071/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:01,  1.29it/s] 67%|██████▋   | 2/3 [00:01<00:00,  1.31it/s]100%|██████████| 3/3 [00:02<00:00,  1.32it/s]100%|██████████| 3/3 [00:02<00:00,  1.32it/s]
Some weights of the model checkpoint at google/vit-large-patch16-224 were not used when initializing ViTModel: ['classifier.weight', 'classifier.bias']
- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViTModel were not initialized from the model checkpoint at google/vit-large-patch16-224 and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading cached processed dataset at /scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/glv2-next-final-f1222a0f34855ac2/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-ea08b590d38a9e74.arrow
Loading cached processed dataset at /scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/disc21-next-final-453d375012a0d071/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-68e0c43e4b40ebc6.arrow
train dataset:  DatasetDict({
    train: Dataset({
        features: ['image'],
        num_rows: 100000
    })
    test: Dataset({
        features: ['image'],
        num_rows: 10000
    })
    validation: Dataset({
        features: ['image'],
        num_rows: 100000
    })
})
ViTModel(
  (embeddings): ViTEmbeddings(
    (patch_embeddings): ViTPatchEmbeddings(
      (projection): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    )
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (encoder): ViTEncoder(
    (layer): ModuleList(
      (0-23): 24 x ViTLayer(
        (attention): ViTAttention(
          (attention): ViTSelfAttention(
            (query): Linear(in_features=1024, out_features=1024, bias=True)
            (key): Linear(in_features=1024, out_features=1024, bias=True)
            (value): Linear(in_features=1024, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (output): ViTSelfOutput(
            (dense): Linear(in_features=1024, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (intermediate): ViTIntermediate(
          (dense): Linear(in_features=1024, out_features=4096, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): ViTOutput(
          (dense): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      )
    )
  )
  (layernorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
  (pooler): GGeM()
)
query_embeddings tensor([[0.5121, 0.7729, 0.3474,  ..., 0.1188, 1.0231, 0.2771],
        [0.5506, 0.6886, 0.1926,  ..., 0.2158, 0.6961, 0.2932],
        [1.0013, 0.9073, 0.1194,  ..., 0.2377, 1.1010, 0.1678],
        ...,
        [0.3466, 0.3442, 0.0947,  ..., 0.0153, 0.6504, 0.2213],
        [0.2507, 0.7736, 0.2405,  ..., 0.2286, 0.5277, 0.4712],
        [0.7516, 1.0764, 0.1894,  ..., 0.0278, 0.8104, 0.3348]],
       device='cuda:0', dtype=torch.float64)
torch.Size([1024])
Computing norms:   0%|          | 0/1129 [00:00<?, ?it/s]Computing norms:   1%|          | 7/1129 [00:00<00:17, 63.37it/s]Computing norms:   1%|          | 14/1129 [00:00<00:17, 65.22it/s]Computing norms:   2%|▏         | 21/1129 [00:00<00:16, 65.82it/s]Computing norms:   2%|▏         | 28/1129 [00:00<00:16, 66.17it/s]Computing norms:   3%|▎         | 35/1129 [00:00<00:16, 64.88it/s]Computing norms:   4%|▎         | 42/1129 [00:00<00:17, 63.78it/s]Computing norms:   4%|▍         | 49/1129 [00:00<00:17, 63.16it/s]Computing norms:   5%|▍         | 56/1129 [00:00<00:17, 62.75it/s]Computing norms:   6%|▌         | 63/1129 [00:00<00:17, 62.53it/s]Computing norms:   6%|▌         | 70/1129 [00:01<00:16, 62.38it/s]Computing norms:   7%|▋         | 77/1129 [00:01<00:16, 62.32it/s]Computing norms:   7%|▋         | 84/1129 [00:01<00:16, 62.23it/s]Computing norms:   8%|▊         | 91/1129 [00:01<00:16, 62.18it/s]Computing norms:   9%|▊         | 98/1129 [00:01<00:16, 62.24it/s]Computing norms:   9%|▉         | 105/1129 [00:01<00:16, 62.27it/s]Computing norms:  10%|▉         | 112/1129 [00:01<00:16, 62.25it/s]Computing norms:  11%|█         | 119/1129 [00:01<00:16, 62.25it/s]Computing norms:  11%|█         | 126/1129 [00:02<00:16, 62.21it/s]Computing norms:  12%|█▏        | 133/1129 [00:02<00:16, 62.09it/s]Computing norms:  12%|█▏        | 140/1129 [00:02<00:15, 61.82it/s]Computing norms:  13%|█▎        | 147/1129 [00:02<00:16, 60.91it/s]Computing norms:  14%|█▎        | 154/1129 [00:02<00:16, 60.30it/s]Computing norms:  14%|█▍        | 161/1129 [00:02<00:16, 59.85it/s]Computing norms:  15%|█▍        | 167/1129 [00:02<00:16, 59.84it/s]Computing norms:  15%|█▌        | 173/1129 [00:02<00:16, 59.70it/s]Computing norms:  16%|█▌        | 180/1129 [00:02<00:15, 59.83it/s]Computing norms:  16%|█▋        | 186/1129 [00:03<00:15, 59.84it/s]Computing norms:  17%|█▋        | 192/1129 [00:03<00:15, 59.73it/s]Computing norms:  18%|█▊        | 198/1129 [00:03<00:15, 59.24it/s]Computing norms:  18%|█▊        | 204/1129 [00:03<00:15, 58.84it/s]Computing norms:  19%|█▊        | 211/1129 [00:03<00:15, 59.47it/s]Computing norms:  19%|█▉        | 217/1129 [00:03<00:15, 59.55it/s]Computing norms:  20%|█▉        | 223/1129 [00:03<00:15, 59.29it/s]Computing norms:  20%|██        | 229/1129 [00:03<00:15, 59.23it/s]Computing norms:  21%|██        | 235/1129 [00:03<00:15, 58.67it/s]Computing norms:  21%|██▏       | 241/1129 [00:03<00:15, 58.83it/s]Computing norms:  22%|██▏       | 247/1129 [00:04<00:15, 58.74it/s]Computing norms:  22%|██▏       | 254/1129 [00:04<00:14, 59.14it/s]Computing norms:  23%|██▎       | 260/1129 [00:04<00:14, 59.00it/s]Computing norms:  24%|██▎       | 266/1129 [00:04<00:14, 59.00it/s]Computing norms:  24%|██▍       | 273/1129 [00:04<00:14, 59.56it/s]Computing norms:  25%|██▍       | 280/1129 [00:04<00:14, 59.94it/s]Computing norms:  25%|██▌       | 286/1129 [00:04<00:14, 59.58it/s]Computing norms:  26%|██▌       | 292/1129 [00:04<00:14, 59.56it/s]Computing norms:  26%|██▋       | 298/1129 [00:04<00:13, 59.39it/s]Computing norms:  27%|██▋       | 304/1129 [00:04<00:13, 59.12it/s]Computing norms:  27%|██▋       | 310/1129 [00:05<00:13, 58.82it/s]Computing norms:  28%|██▊       | 316/1129 [00:05<00:13, 59.08it/s]Computing norms:  29%|██▊       | 322/1129 [00:05<00:13, 58.71it/s]Computing norms:  29%|██▉       | 328/1129 [00:05<00:13, 58.92it/s]Computing norms:  30%|██▉       | 334/1129 [00:05<00:13, 58.71it/s]Computing norms:  30%|███       | 340/1129 [00:05<00:13, 58.72it/s]Computing norms:  31%|███       | 346/1129 [00:05<00:13, 58.34it/s]Computing norms:  31%|███       | 352/1129 [00:05<00:13, 58.78it/s]Computing norms:  32%|███▏      | 358/1129 [00:05<00:13, 58.40it/s]Computing norms:  32%|███▏      | 364/1129 [00:06<00:13, 58.37it/s]Computing norms:  33%|███▎      | 370/1129 [00:06<00:12, 58.65it/s]Computing norms:  33%|███▎      | 376/1129 [00:06<00:12, 58.54it/s]Computing norms:  34%|███▍      | 382/1129 [00:06<00:12, 58.57it/s]Computing norms:  34%|███▍      | 388/1129 [00:06<00:12, 58.33it/s]Computing norms:  35%|███▍      | 394/1129 [00:06<00:12, 58.38it/s]Computing norms:  35%|███▌      | 400/1129 [00:06<00:12, 58.35it/s]Computing norms:  36%|███▌      | 406/1129 [00:06<00:12, 58.56it/s]Computing norms:  36%|███▋      | 412/1129 [00:06<00:12, 58.38it/s]Computing norms:  37%|███▋      | 418/1129 [00:06<00:12, 58.34it/s]Computing norms:  38%|███▊      | 424/1129 [00:07<00:12, 58.26it/s]Computing norms:  38%|███▊      | 430/1129 [00:07<00:12, 57.83it/s]Computing norms:  39%|███▊      | 436/1129 [00:07<00:11, 58.26it/s]Computing norms:  39%|███▉      | 442/1129 [00:07<00:11, 58.59it/s]Computing norms:  40%|███▉      | 448/1129 [00:07<00:11, 58.62it/s]Computing norms:  40%|████      | 454/1129 [00:07<00:11, 58.64it/s]Computing norms:  41%|████      | 460/1129 [00:07<00:11, 58.99it/s]Computing norms:  41%|████▏     | 466/1129 [00:07<00:11, 58.68it/s]Computing norms:  42%|████▏     | 472/1129 [00:07<00:11, 58.30it/s]Computing norms:  42%|████▏     | 478/1129 [00:07<00:11, 58.48it/s]Computing norms:  43%|████▎     | 484/1129 [00:08<00:10, 58.72it/s]Computing norms:  43%|████▎     | 490/1129 [00:08<00:10, 58.80it/s]Computing norms:  44%|████▍     | 496/1129 [00:08<00:10, 58.90it/s]Computing norms:  44%|████▍     | 502/1129 [00:08<00:10, 58.99it/s]Computing norms:  45%|████▌     | 509/1129 [00:08<00:10, 59.42it/s]Computing norms:  46%|████▌     | 515/1129 [00:08<00:10, 59.20it/s]Computing norms:  46%|████▌     | 521/1129 [00:08<00:10, 59.22it/s]Computing norms:  47%|████▋     | 527/1129 [00:08<00:10, 59.20it/s]Computing norms:  47%|████▋     | 533/1129 [00:08<00:10, 58.97it/s]Computing norms:  48%|████▊     | 539/1129 [00:09<00:10, 58.91it/s]Computing norms:  48%|████▊     | 545/1129 [00:09<00:09, 58.96it/s]Computing norms:  49%|████▉     | 551/1129 [00:09<00:09, 59.04it/s]Computing norms:  49%|████▉     | 557/1129 [00:09<00:09, 58.99it/s]Computing norms:  50%|████▉     | 563/1129 [00:09<00:09, 59.02it/s]Computing norms:  50%|█████     | 570/1129 [00:09<00:09, 59.65it/s]Computing norms:  51%|█████     | 576/1129 [00:09<00:09, 59.12it/s]Computing norms:  52%|█████▏    | 582/1129 [00:09<00:09, 59.34it/s]Computing norms:  52%|█████▏    | 588/1129 [00:09<00:09, 58.98it/s]Computing norms:  53%|█████▎    | 594/1129 [00:09<00:09, 58.57it/s]Computing norms:  53%|█████▎    | 600/1129 [00:10<00:08, 58.94it/s]Computing norms:  54%|█████▎    | 606/1129 [00:10<00:08, 59.13it/s]Computing norms:  54%|█████▍    | 612/1129 [00:10<00:08, 59.06it/s]Computing norms:  55%|█████▍    | 619/1129 [00:10<00:08, 59.54it/s]Computing norms:  55%|█████▌    | 625/1129 [00:10<00:08, 59.60it/s]Computing norms:  56%|█████▌    | 631/1129 [00:10<00:08, 59.53it/s]Computing norms:  56%|█████▋    | 637/1129 [00:10<00:08, 59.34it/s]Computing norms:  57%|█████▋    | 643/1129 [00:10<00:08, 59.43it/s]Computing norms:  57%|█████▋    | 649/1129 [00:10<00:08, 59.53it/s]Computing norms:  58%|█████▊    | 655/1129 [00:10<00:07, 59.40it/s]Computing norms:  59%|█████▊    | 661/1129 [00:11<00:07, 59.09it/s]Computing norms:  59%|█████▉    | 667/1129 [00:11<00:07, 59.30it/s]Computing norms:  60%|█████▉    | 673/1129 [00:11<00:07, 59.26it/s]Computing norms:  60%|██████    | 679/1129 [00:11<00:07, 59.26it/s]Computing norms:  61%|██████    | 685/1129 [00:11<00:07, 58.73it/s]Computing norms:  61%|██████    | 691/1129 [00:11<00:07, 58.82it/s]Computing norms:  62%|██████▏   | 697/1129 [00:11<00:07, 58.55it/s]Computing norms:  62%|██████▏   | 703/1129 [00:11<00:07, 58.81it/s]Computing norms:  63%|██████▎   | 709/1129 [00:11<00:07, 58.71it/s]Computing norms:  63%|██████▎   | 715/1129 [00:11<00:07, 59.06it/s]Computing norms:  64%|██████▍   | 721/1129 [00:12<00:06, 59.14it/s]Computing norms:  64%|██████▍   | 727/1129 [00:12<00:06, 58.75it/s]Computing norms:  65%|██████▍   | 733/1129 [00:12<00:06, 58.66it/s]Computing norms:  65%|██████▌   | 739/1129 [00:12<00:06, 58.82it/s]Computing norms:  66%|██████▌   | 745/1129 [00:12<00:06, 58.87it/s]Computing norms:  67%|██████▋   | 751/1129 [00:12<00:06, 58.96it/s]Computing norms:  67%|██████▋   | 757/1129 [00:13<00:20, 18.10it/s]Computing norms:  68%|██████▊   | 763/1129 [00:13<00:16, 22.85it/s]Computing norms:  68%|██████▊   | 769/1129 [00:13<00:12, 27.95it/s]Computing norms:  69%|██████▊   | 775/1129 [00:13<00:10, 33.26it/s]Computing norms:  69%|██████▉   | 781/1129 [00:13<00:09, 38.30it/s]Computing norms:  70%|██████▉   | 788/1129 [00:13<00:07, 43.90it/s]Computing norms:  70%|███████   | 795/1129 [00:14<00:06, 48.51it/s]Computing norms:  71%|███████   | 802/1129 [00:14<00:06, 52.12it/s]Computing norms:  72%|███████▏  | 809/1129 [00:14<00:05, 54.90it/s]Computing norms:  72%|███████▏  | 816/1129 [00:14<00:05, 56.96it/s]Computing norms:  73%|███████▎  | 823/1129 [00:14<00:05, 58.44it/s]Computing norms:  74%|███████▎  | 830/1129 [00:14<00:05, 59.53it/s]Computing norms:  74%|███████▍  | 837/1129 [00:14<00:04, 60.31it/s]Computing norms:  75%|███████▍  | 844/1129 [00:14<00:04, 60.84it/s]Computing norms:  75%|███████▌  | 851/1129 [00:14<00:04, 61.29it/s]Computing norms:  76%|███████▌  | 858/1129 [00:15<00:04, 61.72it/s]Computing norms:  77%|███████▋  | 865/1129 [00:15<00:04, 61.95it/s]Computing norms:  77%|███████▋  | 872/1129 [00:15<00:04, 62.15it/s]Computing norms:  78%|███████▊  | 879/1129 [00:15<00:04, 62.29it/s]Computing norms:  78%|███████▊  | 886/1129 [00:15<00:03, 62.40it/s]Computing norms:  79%|███████▉  | 893/1129 [00:15<00:03, 62.50it/s]Computing norms:  80%|███████▉  | 900/1129 [00:15<00:03, 62.52it/s]Computing norms:  80%|████████  | 907/1129 [00:15<00:03, 62.55it/s]Computing norms:  81%|████████  | 914/1129 [00:15<00:03, 62.56it/s]Computing norms:  82%|████████▏ | 921/1129 [00:16<00:03, 62.57it/s]Computing norms:  82%|████████▏ | 928/1129 [00:16<00:03, 62.58it/s]Computing norms:  83%|████████▎ | 935/1129 [00:16<00:03, 62.58it/s]Computing norms:  83%|████████▎ | 942/1129 [00:16<00:02, 62.56it/s]Computing norms:  84%|████████▍ | 949/1129 [00:16<00:02, 62.58it/s]Computing norms:  85%|████████▍ | 956/1129 [00:16<00:02, 62.59it/s]Computing norms:  85%|████████▌ | 963/1129 [00:16<00:02, 62.61it/s]Computing norms:  86%|████████▌ | 970/1129 [00:16<00:02, 62.62it/s]Computing norms:  87%|████████▋ | 977/1129 [00:17<00:02, 62.59it/s]Computing norms:  87%|████████▋ | 984/1129 [00:17<00:02, 62.61it/s]Computing norms:  88%|████████▊ | 991/1129 [00:17<00:02, 62.61it/s]Computing norms:  88%|████████▊ | 998/1129 [00:17<00:02, 62.58it/s]Computing norms:  89%|████████▉ | 1005/1129 [00:17<00:01, 62.60it/s]Computing norms:  90%|████████▉ | 1012/1129 [00:17<00:01, 62.59it/s]Computing norms:  90%|█████████ | 1019/1129 [00:17<00:01, 62.60it/s]Computing norms:  91%|█████████ | 1026/1129 [00:17<00:01, 62.66it/s]Computing norms:  91%|█████████▏| 1033/1129 [00:17<00:01, 62.68it/s]Computing norms:  92%|█████████▏| 1040/1129 [00:18<00:01, 62.70it/s]Computing norms:  93%|█████████▎| 1047/1129 [00:18<00:01, 62.72it/s]Computing norms:  93%|█████████▎| 1054/1129 [00:18<00:01, 62.72it/s]Computing norms:  94%|█████████▍| 1061/1129 [00:18<00:01, 62.72it/s]Computing norms:  95%|█████████▍| 1068/1129 [00:18<00:00, 62.72it/s]Computing norms:  95%|█████████▌| 1075/1129 [00:18<00:00, 62.42it/s]Computing norms:  96%|█████████▌| 1082/1129 [00:18<00:00, 62.22it/s]Computing norms:  96%|█████████▋| 1089/1129 [00:18<00:00, 62.04it/s]Computing norms:  97%|█████████▋| 1096/1129 [00:18<00:00, 61.90it/s]Computing norms:  98%|█████████▊| 1103/1129 [00:19<00:00, 61.84it/s]Computing norms:  98%|█████████▊| 1110/1129 [00:19<00:00, 61.81it/s]Computing norms:  99%|█████████▉| 1117/1129 [00:19<00:00, 61.71it/s]Computing norms: 100%|█████████▉| 1124/1129 [00:19<00:00, 61.69it/s]Computing norms: 100%|██████████| 1129/1129 [00:19<00:00, 58.05it/s]
Loading cached processed dataset at /scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/glv2-next-final-f1222a0f34855ac2/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-e7b15d5d98ce88ed.arrow
torch.Size([1024])
Computing matrix:   0%|          | 0/1129 [00:00<?, ?it/s]Computing matrix:   4%|▍         | 46/1129 [00:00<00:02, 458.99it/s]Computing matrix:   9%|▉         | 107/1129 [00:00<00:01, 546.05it/s]Computing matrix:  15%|█▍        | 169/1129 [00:00<00:01, 575.53it/s]Computing matrix:  20%|██        | 231/1129 [00:00<00:01, 589.82it/s]Computing matrix:  26%|██▌       | 291/1129 [00:00<00:01, 592.07it/s]Computing matrix:  31%|███       | 352/1129 [00:00<00:01, 595.18it/s]Computing matrix:  36%|███▋      | 412/1129 [00:00<00:01, 587.17it/s]Computing matrix:  42%|████▏     | 471/1129 [00:00<00:01, 582.30it/s]Computing matrix:  47%|████▋     | 530/1129 [00:00<00:01, 579.15it/s]Computing matrix:  52%|█████▏    | 588/1129 [00:01<00:00, 576.98it/s]Computing matrix:  57%|█████▋    | 646/1129 [00:01<00:00, 576.03it/s]Computing matrix:  62%|██████▏   | 704/1129 [00:01<00:00, 575.27it/s]Computing matrix:  67%|██████▋   | 762/1129 [00:01<00:00, 480.53it/s]Computing matrix:  73%|███████▎  | 820/1129 [00:01<00:00, 505.26it/s]Computing matrix:  78%|███████▊  | 878/1129 [00:01<00:00, 524.25it/s]Computing matrix:  83%|████████▎ | 936/1129 [00:01<00:00, 538.64it/s]Computing matrix:  88%|████████▊ | 994/1129 [00:01<00:00, 549.21it/s]Computing matrix:  93%|█████████▎| 1052/1129 [00:01<00:00, 556.97it/s]Computing matrix:  98%|█████████▊| 1110/1129 [00:01<00:00, 562.42it/s]Computing matrix: 100%|██████████| 1129/1129 [00:02<00:00, 557.24it/s]
[[0.84832269 0.81257918 0.85443302 ... 0.82421518 0.84193514 0.84990093]
 [0.85412259 0.78395494 0.83621894 ... 0.83142514 0.81749995 0.84904472]
 [0.84788912 0.79986584 0.86513221 ... 0.85362814 0.84805314 0.84288874]
 ...
 [0.87001485 0.83543048 0.86881427 ... 0.83487961 0.8511382  0.84872347]
 [0.83436215 0.82233708 0.85551469 ... 0.81620218 0.87233756 0.84032664]
 [0.8347036  0.82280056 0.85359325 ... 0.80784497 0.8441694  0.82298221]]
(1129, 10000)
[[ 0.00761005 -0.02813346  0.01372038 ... -0.01649746  0.0012225
   0.00918829]
 [ 0.02833744 -0.04183021  0.0104338  ...  0.00564    -0.00828519
   0.02325958]
 [ 0.00813373 -0.03988955  0.02537682 ...  0.01387275  0.00829775
   0.00313335]
 ...
 [ 0.0185123  -0.01607207  0.01731172 ... -0.01662294 -0.00036435
  -0.00277908]
 [-0.00519925 -0.01722431  0.0159533  ... -0.02335921  0.03277617
   0.00076524]
 [ 0.00362604 -0.00827701  0.02251569 ... -0.0232326   0.01309184
  -0.00809535]]
(1129, 10000)
