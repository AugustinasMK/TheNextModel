{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:31:32.545817Z",
     "end_time": "2023-04-05T13:31:36.045764Z"
    }
   },
   "outputs": [],
   "source": [
    "import augly.image as imaugs\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModel, AutoFeatureExtractor\n",
    "from utils.disc21 import DISC21Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-large-patch16-224 were not used when initializing ViTModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-large-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"google/vit-large-patch16-224\"\n",
    "extractor = AutoFeatureExtractor.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:31:38.109398Z",
     "end_time": "2023-04-05T13:31:45.326772Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "transformation_chain = transforms.Compose(\n",
    "    [\n",
    "        # We first resize the input image to 256x256, and then we take center crop.\n",
    "        transforms.Resize(int((256 / 224) * 224)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=extractor.image_mean, std=extractor.image_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_chain = transforms.Compose(\n",
    "    [\n",
    "        imaugs.Brightness(factor=2.0),\n",
    "        imaugs.RandomRotation(),\n",
    "        imaugs.OneOf([\n",
    "            imaugs.RandomAspectRatio(),\n",
    "            imaugs.RandomBlur(),\n",
    "            imaugs.RandomBrightness(),\n",
    "            imaugs.RandomNoise(),\n",
    "            imaugs.RandomPixelization(),\n",
    "        ]),\n",
    "        imaugs.OneOf([\n",
    "            imaugs.OverlayEmoji(),\n",
    "            imaugs.OverlayStripes(),\n",
    "            imaugs.OverlayText(),\n",
    "        ], p=0.5),\n",
    "        # We first resize the input image to 256x256, and then we take center crop.\n",
    "        transforms.Resize(int((256 / 224) * 224)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=extractor.image_mean, std=extractor.image_std),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:32:36.395988Z",
     "end_time": "2023-04-05T13:32:36.438017Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "class DISC21(Dataset):\n",
    "    def __init__(self, df, subset='train', transform=None, augmentations=None):\n",
    "        self.is_train = subset == 'train'\n",
    "        self.is_gallery = subset == 'gallery'\n",
    "        self.transform = transform\n",
    "        self.augmentations = transform if augmentations is None else augmentations\n",
    "\n",
    "        if self.is_train:\n",
    "            self.images = df.train\n",
    "        elif self.is_gallery:\n",
    "            self.images = df.gallery\n",
    "        else:\n",
    "            self.images = df.query\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        full_name, name = self.images[index]\n",
    "        anchor_img = Image.open(full_name)\n",
    "\n",
    "        if self.is_train:\n",
    "            positive_img = anchor_img\n",
    "\n",
    "            if self.transform:\n",
    "                anchor_img = self.transform(anchor_img)\n",
    "                positive_img = self.augmentations(positive_img)\n",
    "\n",
    "            return anchor_img, positive_img, index, name\n",
    "        else:\n",
    "            if self.transform:\n",
    "                anchor_img = self.transform(anchor_img)\n",
    "            return anchor_img, name\n",
    "\n",
    "    def get_negatives(self, positive_indexes: list, num_negatives: int = 2):\n",
    "        pos_negative_indexes = []\n",
    "        for i in range(len(self)):\n",
    "            if i not in positive_indexes:\n",
    "                pos_negative_indexes.append(i)\n",
    "\n",
    "        for i in pos_negative_indexes:\n",
    "            if i in positive_indexes:\n",
    "                raise Exception('Negative index is in positive indexes')\n",
    "\n",
    "        negative_indexes = random.sample(pos_negative_indexes, num_negatives)\n",
    "        negative_imgs = []\n",
    "        for i in negative_indexes:\n",
    "            full_name, name = self.images[i]\n",
    "            negative_img = Image.open(full_name)\n",
    "            if self.transform:\n",
    "                negative_img = self.augmentations(negative_img)\n",
    "            negative_imgs.append(negative_img)\n",
    "\n",
    "        return torch.stack(negative_imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:32:37.352482Z",
     "end_time": "2023-04-05T13:32:37.361976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISC21Definition dataset loaded\n",
      "  subset   | # ids | # images\n",
      "  ---------------------------\n",
      "  train    | 100000 |   100000\n",
      "  gallery  | 100000 |   100000\n",
      "  query    |  10000 |    10000\n"
     ]
    }
   ],
   "source": [
    "train_df = DISC21Definition('/media/augustinas/T7/DISC2021/SmallData/images/')\n",
    "train_ds = DISC21(train_df, subset='train', transform=transformation_chain, augmentations=augmentation_chain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:32:38.617418Z",
     "end_time": "2023-04-05T13:32:44.131188Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:32:46.294177Z",
     "end_time": "2023-04-05T13:32:46.296542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "anchor_img, positive_img, index, name = next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:32:47.581341Z",
     "end_time": "2023-04-05T13:32:48.368546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([4, 3, 224, 224]),\n torch.Size([4, 3, 224, 224]),\n tensor([0, 1, 2, 3]),\n ('T000001.jpg', 'T000004.jpg', 'T000007.jpg', 'T000013.jpg'))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_img.shape, positive_img.shape, index, name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:32:49.130182Z",
     "end_time": "2023-04-05T13:32:49.137043Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(index.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:32:50.910806Z",
     "end_time": "2023-04-05T13:32:50.933794Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "negatives = train_ds.get_negatives(index.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:32:52.871249Z",
     "end_time": "2023-04-05T13:32:53.533803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 224, 224])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:32:56.957383Z",
     "end_time": "2023-04-05T13:32:56.965775Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "anchor_out = model(anchor_img).last_hidden_state\n",
    "positive_out = model(positive_img).last_hidden_state\n",
    "negative_out = model(negatives).last_hidden_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:33:56.569325Z",
     "end_time": "2023-04-05T13:34:02.877950Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([4, 197, 1024]),\n torch.Size([4, 197, 1024]),\n torch.Size([2, 197, 1024]))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_out.shape, positive_out.shape, negative_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:34:05.034342Z",
     "end_time": "2023-04-05T13:34:05.045797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pdist = torch.nn.PairwiseDistance(p=2)\n",
    "    pos_matrix = pdist(torch.flatten(anchor_out, start_dim=1), torch.flatten(positive_out, start_dim=1))\n",
    "    pos_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:35:13.092016Z",
     "end_time": "2023-04-05T13:35:13.100980Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_matrix.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:34:26.263346Z",
     "end_time": "2023-04-05T13:34:26.271405Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([457.5093, 470.1355, 453.8908, 478.1834])\n"
     ]
    }
   ],
   "source": [
    "print(pos_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:35:20.108179Z",
     "end_time": "2023-04-05T13:35:20.112031Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    neg_matrix = torch.cdist(torch.flatten(anchor_out, start_dim=1), torch.flatten(negative_out, start_dim=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:35:33.677429Z",
     "end_time": "2023-04-05T13:35:33.718156Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 2])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_matrix.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:35:36.254938Z",
     "end_time": "2023-04-05T13:35:36.261996Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[477.7953, 478.3789],\n",
      "        [485.2651, 480.8302],\n",
      "        [483.1764, 478.4398],\n",
      "        [480.6655, 482.2917]])\n"
     ]
    }
   ],
   "source": [
    "print(neg_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:35:37.632103Z",
     "end_time": "2023-04-05T13:35:37.642760Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "loss = -1 * neg_matrix + pos_matrix[:, None] + 0.3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:44:06.619962Z",
     "end_time": "2023-04-05T13:44:06.662007Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-19.9860, -20.5696],\n        [-14.8297, -10.3948],\n        [-28.9855, -24.2490],\n        [ -2.1821,  -3.8082]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T13:44:14.757496Z",
     "end_time": "2023-04-05T13:44:14.774695Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([-19.9860, -10.3948, -24.2490,  -2.1821]),\nindices=tensor([0, 1, 1, 0]))"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(loss, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T14:21:58.951799Z",
     "end_time": "2023-04-05T14:21:58.959541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.min(\nvalues=tensor([477.7953, 480.8302, 478.4398, 480.6655]),\nindices=tensor([0, 1, 1, 0]))"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(neg_matrix, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T14:22:16.938240Z",
     "end_time": "2023-04-05T14:22:16.950487Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.min(\nvalues=tensor([477.7953, 480.8302, 478.4398, 480.6655]),\nindices=tensor([0, 1, 1, 0]))"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bluh = torch.min(neg_matrix, dim=1)\n",
    "bluh"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T14:37:06.341534Z",
     "end_time": "2023-04-05T14:37:06.347154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "xx = negative_out[bluh]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T14:36:09.302748Z",
     "end_time": "2023-04-05T14:36:09.306799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 197, 1024])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T14:36:10.538678Z",
     "end_time": "2023-04-05T14:36:10.541554Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.4705,  0.4278, -1.5170,  ..., -0.5304,  1.4812,  0.6127],\n         [ 0.5671,  0.1269,  0.6412,  ..., -0.5248, -0.1459,  0.3352],\n         [ 0.6669,  0.9921,  0.2923,  ..., -0.1060, -0.0841,  0.1201],\n         ...,\n         [ 0.6194,  0.9290, -1.1486,  ..., -0.1816,  0.8863, -0.2848],\n         [ 1.4237,  0.7164,  1.3291,  ...,  0.1410,  1.0244, -0.2277],\n         [ 0.2695,  0.8971, -1.1627,  ...,  0.8704,  1.1855,  0.1758]],\n\n        [[ 0.1253, -0.1360,  0.1263,  ..., -0.0542,  0.2329,  0.1086],\n         [-0.1860, -0.3081,  1.1543,  ...,  0.1272,  0.6510,  1.6323],\n         [ 0.4400,  0.8774,  1.0815,  ...,  0.3712,  0.2753,  0.4012],\n         ...,\n         [ 0.9806,  0.8069, -0.9632,  ..., -1.1620, -0.5529,  0.6621],\n         [-0.5336,  0.5281, -1.9177,  ..., -0.5603,  1.0208,  0.8507],\n         [ 0.6068,  0.2072,  0.6100,  ..., -1.4635,  0.1104,  0.6014]],\n\n        [[ 0.1253, -0.1360,  0.1263,  ..., -0.0542,  0.2329,  0.1086],\n         [-0.1860, -0.3081,  1.1543,  ...,  0.1272,  0.6510,  1.6323],\n         [ 0.4400,  0.8774,  1.0815,  ...,  0.3712,  0.2753,  0.4012],\n         ...,\n         [ 0.9806,  0.8069, -0.9632,  ..., -1.1620, -0.5529,  0.6621],\n         [-0.5336,  0.5281, -1.9177,  ..., -0.5603,  1.0208,  0.8507],\n         [ 0.6068,  0.2072,  0.6100,  ..., -1.4635,  0.1104,  0.6014]],\n\n        [[ 0.4705,  0.4278, -1.5170,  ..., -0.5304,  1.4812,  0.6127],\n         [ 0.5671,  0.1269,  0.6412,  ..., -0.5248, -0.1459,  0.3352],\n         [ 0.6669,  0.9921,  0.2923,  ..., -0.1060, -0.0841,  0.1201],\n         ...,\n         [ 0.6194,  0.9290, -1.1486,  ..., -0.1816,  0.8863, -0.2848],\n         [ 1.4237,  0.7164,  1.3291,  ...,  0.1410,  1.0244, -0.2277],\n         [ 0.2695,  0.8971, -1.1627,  ...,  0.8704,  1.1855,  0.1758]]],\n       grad_fn=<IndexBackward0>)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T14:36:41.743952Z",
     "end_time": "2023-04-05T14:36:41.805601Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pdist = torch.nn.PairwiseDistance(p=2)\n",
    "    xxf_matrix = pdist(torch.flatten(anchor_out, start_dim=1), torch.flatten(xx, start_dim=1))\n",
    "    xxf_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T14:39:15.147891Z",
     "end_time": "2023-04-05T14:39:15.147994Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxf_matrix.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T14:39:16.083259Z",
     "end_time": "2023-04-05T14:39:16.083320Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([477.8062, 480.8405, 478.4513, 480.6765])\n"
     ]
    }
   ],
   "source": [
    "print(xxf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T14:39:16.798189Z",
     "end_time": "2023-04-05T14:39:16.798248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
