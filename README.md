# TheNextModel

This repo saves the work files and results of my Master Thesis. Summary of work:

As data volumes continue to grow, it is no longer optimal to manually search for similar images in large image datasets. Automation of the evaluation of image similarity is needed to evaluate the similarity in a short timeframe and to reduce the subjectivity of the evaluation. The aim of this work is to propose a new method for the evaluation of image similarity in undefined subject domains. Existing similarity evaluation methods (GIST, MultiGrain, HOW, VisionForce and methods adapted to the classification task) and a newly proposed method based on vision transformers and the quadruplet loss function are investigated. The methods are evaluated using the „DISC21“ and „Google Landmarks Dataset v2“ (GLDv2) datasets. VisionForce, HOW and the author’s proposed method showed the best precision on the „DISC21“ dataset, while the method based on classification models showed the worst results. The best precision on the „GLDv2“ dataset was achieved by the HOW method and the author’s proposed method. The GIST method was found to be the fastest when the performance of the models was tested. The best performing HOW and VisionForce methods have the lowest feature extraction speed. The author’s proposed method is ranked second in terms of performance.
