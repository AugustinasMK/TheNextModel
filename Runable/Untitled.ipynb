{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20978b1-87ad-4d8b-93a4-498139deae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import augly.image as imaugs\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModel, AutoFeatureExtractor\n",
    "from utils.disc21 import DISC21Definition, DISC21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7eb794-ef77-4ffe-b19b-8fad0d6d81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07435e4-86b7-447e-b945-af2478c4cb2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m augmentation_chain \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m      2\u001b[0m         [\n\u001b[1;32m      3\u001b[0m             imaugs\u001b[38;5;241m.\u001b[39mBrightness(factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m),\n\u001b[1;32m      4\u001b[0m             imaugs\u001b[38;5;241m.\u001b[39mRandomRotation(),\n\u001b[1;32m      5\u001b[0m             imaugs\u001b[38;5;241m.\u001b[39mOneOf([\n\u001b[1;32m      6\u001b[0m                 imaugs\u001b[38;5;241m.\u001b[39mRandomAspectRatio(),\n\u001b[1;32m      7\u001b[0m                 imaugs\u001b[38;5;241m.\u001b[39mRandomBlur(),\n\u001b[1;32m      8\u001b[0m                 imaugs\u001b[38;5;241m.\u001b[39mRandomBrightness(),\n\u001b[1;32m      9\u001b[0m                 imaugs\u001b[38;5;241m.\u001b[39mRandomNoise(),\n\u001b[1;32m     10\u001b[0m                 imaugs\u001b[38;5;241m.\u001b[39mRandomPixelization(),\n\u001b[1;32m     11\u001b[0m             ]),\n\u001b[1;32m     12\u001b[0m             imaugs\u001b[38;5;241m.\u001b[39mOneOf([\n\u001b[1;32m     13\u001b[0m                 imaugs\u001b[38;5;241m.\u001b[39mOverlayEmoji(),\n\u001b[1;32m     14\u001b[0m                 imaugs\u001b[38;5;241m.\u001b[39mOverlayStripes(),\n\u001b[1;32m     15\u001b[0m                 imaugs\u001b[38;5;241m.\u001b[39mOverlayText(),\n\u001b[1;32m     16\u001b[0m             ]),\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;66;03m# We first resize the input image to 256x256, and then we take center crop.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m             transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;28mint\u001b[39m((\u001b[38;5;241m256\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m224\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m224\u001b[39m)),\n\u001b[1;32m     19\u001b[0m             transforms\u001b[38;5;241m.\u001b[39mCenterCrop(\u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m     20\u001b[0m             transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m---> 21\u001b[0m             transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m\u001b[43mextractor\u001b[49m\u001b[38;5;241m.\u001b[39mimage_mean, std\u001b[38;5;241m=\u001b[39mextractor\u001b[38;5;241m.\u001b[39mimage_std),\n\u001b[1;32m     22\u001b[0m         ]\n\u001b[1;32m     23\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extractor' is not defined"
     ]
    }
   ],
   "source": [
    "augmentation_chain = transforms.Compose(\n",
    "        [\n",
    "            imaugs.Brightness(factor=2.0),\n",
    "            imaugs.RandomRotation(),\n",
    "            imaugs.OneOf([\n",
    "                imaugs.RandomAspectRatio(),\n",
    "                imaugs.RandomBlur(),\n",
    "                imaugs.RandomBrightness(),\n",
    "                imaugs.RandomNoise(),\n",
    "                imaugs.RandomPixelization(),\n",
    "            ]),\n",
    "            imaugs.OneOf([\n",
    "                imaugs.OverlayEmoji(),\n",
    "                imaugs.OverlayStripes(),\n",
    "                imaugs.OverlayText(),\n",
    "            ]),\n",
    "            # We first resize the input image to 256x256, and then we take center crop.\n",
    "            transforms.Resize(int((256 / 224) * 224)),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=extractor.image_mean, std=extractor.image_std),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69424ed2-947c-474b-b885-4d1be0fbc5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
