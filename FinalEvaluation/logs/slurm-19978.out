/scratch/lustre/home/auma4493/TheNextModel/FinalEvaluation
args: Namespace(batch_size=32, dataset='glv2_t', model_checkpoint='/scratch/lustre/home/auma4493/TheNextModel/FinalTraining/checkpoints/disc/trained_model_20_20.pth', model_name='google/vit-large-patch16-224', model_type='disc', use_GeM=True)
Resolving data files:   0%|          | 0/138520 [00:00<?, ?it/s]Resolving data files:  24%|██▍       | 33862/138520 [00:00<00:00, 338600.95it/s]Resolving data files:  49%|████▉     | 67723/138520 [00:00<00:00, 284908.25it/s]Resolving data files:  72%|███████▏  | 99610/138520 [00:00<00:00, 298969.57it/s]Resolving data files:  96%|█████████▌| 132561/138520 [00:00<00:00, 278106.01it/s]Resolving data files: 100%|██████████| 138520/138520 [00:01<00:00, 84450.20it/s] 
Resolving data files:   0%|          | 0/1129 [00:00<?, ?it/s]Resolving data files: 100%|██████████| 1129/1129 [00:00<00:00, 21363.69it/s]
Resolving data files:   0%|          | 0/10000 [00:00<?, ?it/s]Resolving data files:  87%|████████▋ | 8715/10000 [00:00<00:00, 78582.00it/s]Resolving data files: 100%|██████████| 10000/10000 [00:00<00:00, 49768.25it/s]
Found cached dataset imagefolder (/scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/glv2-next-final-f1222a0f34855ac2/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:01,  1.59it/s] 67%|██████▋   | 2/3 [00:01<00:00,  1.58it/s]100%|██████████| 3/3 [00:01<00:00,  1.61it/s]100%|██████████| 3/3 [00:01<00:00,  1.60it/s]
main dataset:  DatasetDict({
    train: Dataset({
        features: ['image'],
        num_rows: 138520
    })
    test: Dataset({
        features: ['image'],
        num_rows: 1129
    })
    validation: Dataset({
        features: ['image'],
        num_rows: 10000
    })
})
Resolving data files:   0%|          | 0/100000 [00:00<?, ?it/s]Resolving data files:  33%|███▎      | 33062/100000 [00:00<00:00, 329784.51it/s]Resolving data files:  73%|███████▎  | 72685/100000 [00:00<00:00, 368817.68it/s]Resolving data files: 100%|██████████| 100000/100000 [00:01<00:00, 59203.56it/s]
Resolving data files:   0%|          | 0/10000 [00:00<?, ?it/s]Resolving data files:  81%|████████▏ | 8148/10000 [00:00<00:00, 77428.39it/s]Resolving data files: 100%|██████████| 10000/10000 [00:00<00:00, 18255.22it/s]
Resolving data files:   0%|          | 0/100000 [00:00<?, ?it/s]Resolving data files:  18%|█▊        | 17766/100000 [00:00<00:00, 162901.79it/s]Resolving data files:  37%|███▋      | 36847/100000 [00:00<00:00, 166512.57it/s]Resolving data files:  57%|█████▋    | 56507/100000 [00:00<00:00, 174244.24it/s]Resolving data files:  74%|███████▍  | 73946/100000 [00:00<00:00, 158520.52it/s]Resolving data files:  90%|████████▉ | 89937/100000 [00:01<00:00, 50377.46it/s] Resolving data files: 100%|██████████| 100000/100000 [00:03<00:00, 30006.62it/s]
Found cached dataset imagefolder (/scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/disc21-next-final-453d375012a0d071/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:01,  1.08it/s] 67%|██████▋   | 2/3 [00:01<00:00,  1.10it/s]100%|██████████| 3/3 [00:02<00:00,  1.13it/s]100%|██████████| 3/3 [00:02<00:00,  1.12it/s]
Some weights of the model checkpoint at google/vit-large-patch16-224 were not used when initializing ViTModel: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ViTModel were not initialized from the model checkpoint at google/vit-large-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading cached processed dataset at /scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/glv2-next-final-f1222a0f34855ac2/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-83677ef57cda4518.arrow
Loading cached processed dataset at /scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/disc21-next-final-453d375012a0d071/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-a842da5693718134.arrow
train dataset:  DatasetDict({
    train: Dataset({
        features: ['image'],
        num_rows: 100000
    })
    test: Dataset({
        features: ['image'],
        num_rows: 10000
    })
    validation: Dataset({
        features: ['image'],
        num_rows: 100000
    })
})
ViTModel(
  (embeddings): ViTEmbeddings(
    (patch_embeddings): ViTPatchEmbeddings(
      (projection): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    )
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (encoder): ViTEncoder(
    (layer): ModuleList(
      (0-23): 24 x ViTLayer(
        (attention): ViTAttention(
          (attention): ViTSelfAttention(
            (query): Linear(in_features=1024, out_features=1024, bias=True)
            (key): Linear(in_features=1024, out_features=1024, bias=True)
            (value): Linear(in_features=1024, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (output): ViTSelfOutput(
            (dense): Linear(in_features=1024, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (intermediate): ViTIntermediate(
          (dense): Linear(in_features=1024, out_features=4096, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): ViTOutput(
          (dense): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      )
    )
  )
  (layernorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
  (pooler): GGeM()
)
query_embeddings tensor([[0.6917, 0.6429, 0.3240,  ..., 0.2776, 0.6978, 0.7957],
        [0.8662, 0.6835, 0.1496,  ..., 0.2571, 0.6861, 0.8795],
        [1.1871, 1.1602, 0.1333,  ..., 0.6178, 1.0133, 0.7181],
        ...,
        [0.3618, 0.2826, 0.0664,  ..., 0.4325, 0.3838, 0.7408],
        [0.3223, 0.5597, 0.3001,  ..., 0.2965, 0.5574, 1.1797],
        [1.1286, 0.9357, 0.1382,  ..., 0.1743, 0.6674, 0.9435]],
       device='cuda:0', dtype=torch.float64)
torch.Size([1024])
Computing norms:   0%|          | 0/1129 [00:00<?, ?it/s]Computing norms:   1%|          | 7/1129 [00:00<00:18, 61.89it/s]Computing norms:   1%|          | 14/1129 [00:00<00:17, 64.12it/s]Computing norms:   2%|▏         | 21/1129 [00:00<00:17, 64.81it/s]Computing norms:   2%|▏         | 28/1129 [00:00<00:16, 65.07it/s]Computing norms:   3%|▎         | 35/1129 [00:00<00:17, 63.18it/s]Computing norms:   4%|▎         | 42/1129 [00:00<00:17, 62.23it/s]Computing norms:   4%|▍         | 49/1129 [00:00<00:17, 61.59it/s]Computing norms:   5%|▍         | 56/1129 [00:00<00:17, 61.19it/s]Computing norms:   6%|▌         | 63/1129 [00:01<00:17, 60.79it/s]Computing norms:   6%|▌         | 70/1129 [00:01<00:17, 60.57it/s]Computing norms:   7%|▋         | 77/1129 [00:01<00:17, 60.24it/s]Computing norms:   7%|▋         | 84/1129 [00:01<00:17, 60.25it/s]Computing norms:   8%|▊         | 91/1129 [00:01<00:17, 60.22it/s]Computing norms:   9%|▊         | 98/1129 [00:01<00:17, 60.13it/s]Computing norms:   9%|▉         | 105/1129 [00:01<00:17, 59.98it/s]Computing norms:  10%|▉         | 111/1129 [00:01<00:17, 59.80it/s]Computing norms:  10%|█         | 118/1129 [00:01<00:16, 60.05it/s]Computing norms:  11%|█         | 125/1129 [00:02<00:16, 60.16it/s]Computing norms:  12%|█▏        | 132/1129 [00:02<00:16, 60.21it/s]Computing norms:  12%|█▏        | 139/1129 [00:02<00:16, 60.21it/s]Computing norms:  13%|█▎        | 146/1129 [00:02<00:16, 60.01it/s]Computing norms:  14%|█▎        | 153/1129 [00:02<00:16, 59.80it/s]Computing norms:  14%|█▍        | 160/1129 [00:02<00:16, 59.85it/s]Computing norms:  15%|█▍        | 167/1129 [00:02<00:16, 59.99it/s]Computing norms:  15%|█▌        | 174/1129 [00:02<00:15, 60.13it/s]Computing norms:  16%|█▌        | 181/1129 [00:02<00:15, 60.28it/s]Computing norms:  17%|█▋        | 188/1129 [00:03<00:15, 60.29it/s]Computing norms:  17%|█▋        | 195/1129 [00:03<00:15, 60.37it/s]Computing norms:  18%|█▊        | 202/1129 [00:03<00:15, 60.55it/s]Computing norms:  19%|█▊        | 209/1129 [00:03<00:15, 60.65it/s]Computing norms:  19%|█▉        | 216/1129 [00:03<00:15, 60.71it/s]Computing norms:  20%|█▉        | 223/1129 [00:03<00:14, 60.67it/s]Computing norms:  20%|██        | 230/1129 [00:03<00:14, 60.77it/s]Computing norms:  21%|██        | 237/1129 [00:03<00:14, 60.77it/s]Computing norms:  22%|██▏       | 244/1129 [00:04<00:14, 60.58it/s]Computing norms:  22%|██▏       | 251/1129 [00:04<00:14, 60.67it/s]Computing norms:  23%|██▎       | 258/1129 [00:04<00:14, 60.88it/s]Computing norms:  23%|██▎       | 265/1129 [00:04<00:14, 60.95it/s]Computing norms:  24%|██▍       | 272/1129 [00:04<00:14, 61.04it/s]Computing norms:  25%|██▍       | 279/1129 [00:04<00:13, 61.09it/s]Computing norms:  25%|██▌       | 286/1129 [00:04<00:13, 61.22it/s]Computing norms:  26%|██▌       | 293/1129 [00:04<00:13, 61.09it/s]Computing norms:  27%|██▋       | 300/1129 [00:04<00:13, 61.05it/s]Computing norms:  27%|██▋       | 307/1129 [00:05<00:13, 61.06it/s]Computing norms:  28%|██▊       | 314/1129 [00:05<00:13, 60.95it/s]Computing norms:  28%|██▊       | 321/1129 [00:05<00:13, 60.89it/s]Computing norms:  29%|██▉       | 328/1129 [00:05<00:13, 60.89it/s]Computing norms:  30%|██▉       | 335/1129 [00:05<00:13, 60.96it/s]Computing norms:  30%|███       | 342/1129 [00:05<00:12, 61.05it/s]Computing norms:  31%|███       | 349/1129 [00:05<00:12, 60.87it/s]Computing norms:  32%|███▏      | 356/1129 [00:05<00:12, 60.76it/s]Computing norms:  32%|███▏      | 363/1129 [00:05<00:12, 60.64it/s]Computing norms:  33%|███▎      | 370/1129 [00:06<00:12, 60.32it/s]Computing norms:  33%|███▎      | 377/1129 [00:06<00:12, 60.21it/s]Computing norms:  34%|███▍      | 384/1129 [00:06<00:12, 60.18it/s]Computing norms:  35%|███▍      | 391/1129 [00:06<00:12, 60.33it/s]Computing norms:  35%|███▌      | 398/1129 [00:06<00:12, 60.36it/s]Computing norms:  36%|███▌      | 405/1129 [00:06<00:12, 60.28it/s]Computing norms:  36%|███▋      | 412/1129 [00:06<00:11, 60.31it/s]Computing norms:  37%|███▋      | 419/1129 [00:06<00:11, 60.34it/s]Computing norms:  38%|███▊      | 426/1129 [00:07<00:11, 60.43it/s]Computing norms:  38%|███▊      | 433/1129 [00:07<00:11, 60.33it/s]Computing norms:  39%|███▉      | 440/1129 [00:07<00:11, 60.35it/s]Computing norms:  40%|███▉      | 447/1129 [00:07<00:11, 60.32it/s]Computing norms:  40%|████      | 454/1129 [00:07<00:11, 60.18it/s]Computing norms:  41%|████      | 461/1129 [00:07<00:11, 60.17it/s]Computing norms:  41%|████▏     | 468/1129 [00:07<00:10, 60.26it/s]Computing norms:  42%|████▏     | 475/1129 [00:07<00:10, 60.24it/s]Computing norms:  43%|████▎     | 482/1129 [00:07<00:10, 60.24it/s]Computing norms:  43%|████▎     | 489/1129 [00:08<00:10, 60.06it/s]Computing norms:  44%|████▍     | 496/1129 [00:08<00:10, 60.26it/s]Computing norms:  45%|████▍     | 503/1129 [00:08<00:10, 60.45it/s]Computing norms:  45%|████▌     | 510/1129 [00:08<00:10, 60.60it/s]Computing norms:  46%|████▌     | 517/1129 [00:08<00:10, 60.46it/s]Computing norms:  46%|████▋     | 524/1129 [00:08<00:10, 60.37it/s]Computing norms:  47%|████▋     | 531/1129 [00:08<00:09, 60.46it/s]Computing norms:  48%|████▊     | 538/1129 [00:08<00:09, 60.52it/s]Computing norms:  48%|████▊     | 545/1129 [00:08<00:09, 60.61it/s]Computing norms:  49%|████▉     | 552/1129 [00:09<00:09, 60.84it/s]Computing norms:  50%|████▉     | 559/1129 [00:09<00:09, 60.72it/s]Computing norms:  50%|█████     | 566/1129 [00:09<00:09, 60.44it/s]Computing norms:  51%|█████     | 573/1129 [00:09<00:09, 60.36it/s]Computing norms:  51%|█████▏    | 580/1129 [00:09<00:09, 60.58it/s]Computing norms:  52%|█████▏    | 587/1129 [00:09<00:08, 60.82it/s]Computing norms:  53%|█████▎    | 594/1129 [00:09<00:08, 60.86it/s]Computing norms:  53%|█████▎    | 601/1129 [00:09<00:08, 60.37it/s]Computing norms:  54%|█████▍    | 608/1129 [00:10<00:08, 60.38it/s]Computing norms:  54%|█████▍    | 615/1129 [00:10<00:08, 60.35it/s]Computing norms:  55%|█████▌    | 622/1129 [00:10<00:08, 60.51it/s]Computing norms:  56%|█████▌    | 629/1129 [00:10<00:08, 60.45it/s]Computing norms:  56%|█████▋    | 636/1129 [00:10<00:08, 60.35it/s]Computing norms:  57%|█████▋    | 643/1129 [00:10<00:08, 60.19it/s]Computing norms:  58%|█████▊    | 650/1129 [00:10<00:07, 60.25it/s]Computing norms:  58%|█████▊    | 657/1129 [00:10<00:07, 60.39it/s]Computing norms:  59%|█████▉    | 664/1129 [00:10<00:07, 60.30it/s]Computing norms:  59%|█████▉    | 671/1129 [00:11<00:07, 60.43it/s]Computing norms:  60%|██████    | 678/1129 [00:11<00:07, 60.54it/s]Computing norms:  61%|██████    | 685/1129 [00:11<00:07, 60.71it/s]Computing norms:  61%|██████▏   | 692/1129 [00:11<00:07, 60.56it/s]Computing norms:  62%|██████▏   | 699/1129 [00:11<00:07, 60.61it/s]Computing norms:  63%|██████▎   | 706/1129 [00:11<00:06, 60.53it/s]Computing norms:  63%|██████▎   | 713/1129 [00:11<00:06, 60.59it/s]Computing norms:  64%|██████▍   | 720/1129 [00:11<00:06, 60.52it/s]Computing norms:  64%|██████▍   | 727/1129 [00:11<00:06, 60.61it/s]Computing norms:  65%|██████▌   | 734/1129 [00:12<00:06, 60.69it/s]Computing norms:  66%|██████▌   | 741/1129 [00:12<00:17, 21.61it/s]Computing norms:  66%|██████▋   | 748/1129 [00:13<00:14, 26.79it/s]Computing norms:  67%|██████▋   | 755/1129 [00:13<00:11, 32.22it/s]Computing norms:  67%|██████▋   | 762/1129 [00:13<00:09, 37.60it/s]Computing norms:  68%|██████▊   | 769/1129 [00:13<00:08, 42.57it/s]Computing norms:  69%|██████▊   | 776/1129 [00:13<00:07, 46.95it/s]Computing norms:  69%|██████▉   | 783/1129 [00:13<00:06, 50.49it/s]Computing norms:  70%|██████▉   | 790/1129 [00:13<00:06, 53.20it/s]Computing norms:  71%|███████   | 797/1129 [00:13<00:05, 55.38it/s]Computing norms:  71%|███████   | 804/1129 [00:13<00:05, 57.01it/s]Computing norms:  72%|███████▏  | 811/1129 [00:14<00:05, 58.20it/s]Computing norms:  72%|███████▏  | 818/1129 [00:14<00:05, 59.11it/s]Computing norms:  73%|███████▎  | 825/1129 [00:14<00:05, 59.72it/s]Computing norms:  74%|███████▎  | 832/1129 [00:14<00:04, 59.97it/s]Computing norms:  74%|███████▍  | 839/1129 [00:14<00:04, 60.39it/s]Computing norms:  75%|███████▍  | 846/1129 [00:14<00:04, 60.73it/s]Computing norms:  76%|███████▌  | 853/1129 [00:14<00:04, 60.84it/s]Computing norms:  76%|███████▌  | 860/1129 [00:14<00:04, 60.94it/s]Computing norms:  77%|███████▋  | 867/1129 [00:14<00:04, 61.05it/s]Computing norms:  77%|███████▋  | 874/1129 [00:15<00:04, 61.22it/s]Computing norms:  78%|███████▊  | 881/1129 [00:15<00:04, 61.18it/s]Computing norms:  79%|███████▊  | 888/1129 [00:15<00:03, 60.58it/s]Computing norms:  79%|███████▉  | 895/1129 [00:15<00:03, 60.58it/s]Computing norms:  80%|███████▉  | 902/1129 [00:15<00:03, 60.63it/s]Computing norms:  81%|████████  | 909/1129 [00:15<00:03, 60.71it/s]Computing norms:  81%|████████  | 916/1129 [00:15<00:03, 60.85it/s]Computing norms:  82%|████████▏ | 923/1129 [00:15<00:03, 61.02it/s]Computing norms:  82%|████████▏ | 930/1129 [00:16<00:03, 61.04it/s]Computing norms:  83%|████████▎ | 937/1129 [00:16<00:03, 60.99it/s]Computing norms:  84%|████████▎ | 944/1129 [00:16<00:03, 60.87it/s]Computing norms:  84%|████████▍ | 951/1129 [00:16<00:02, 60.93it/s]Computing norms:  85%|████████▍ | 958/1129 [00:16<00:02, 60.85it/s]Computing norms:  85%|████████▌ | 965/1129 [00:16<00:02, 60.88it/s]Computing norms:  86%|████████▌ | 972/1129 [00:16<00:02, 60.97it/s]Computing norms:  87%|████████▋ | 979/1129 [00:16<00:02, 61.07it/s]Computing norms:  87%|████████▋ | 986/1129 [00:16<00:02, 61.22it/s]Computing norms:  88%|████████▊ | 993/1129 [00:17<00:02, 61.22it/s]Computing norms:  89%|████████▊ | 1000/1129 [00:17<00:02, 61.07it/s]Computing norms:  89%|████████▉ | 1007/1129 [00:17<00:01, 61.07it/s]Computing norms:  90%|████████▉ | 1014/1129 [00:17<00:01, 61.15it/s]Computing norms:  90%|█████████ | 1021/1129 [00:17<00:01, 61.22it/s]Computing norms:  91%|█████████ | 1028/1129 [00:17<00:01, 61.24it/s]Computing norms:  92%|█████████▏| 1035/1129 [00:17<00:01, 61.26it/s]Computing norms:  92%|█████████▏| 1042/1129 [00:17<00:01, 61.26it/s]Computing norms:  93%|█████████▎| 1049/1129 [00:17<00:01, 61.44it/s]Computing norms:  94%|█████████▎| 1056/1129 [00:18<00:01, 61.57it/s]Computing norms:  94%|█████████▍| 1063/1129 [00:18<00:01, 61.67it/s]Computing norms:  95%|█████████▍| 1070/1129 [00:18<00:00, 61.41it/s]Computing norms:  95%|█████████▌| 1077/1129 [00:18<00:00, 61.14it/s]Computing norms:  96%|█████████▌| 1084/1129 [00:18<00:00, 61.06it/s]Computing norms:  97%|█████████▋| 1091/1129 [00:18<00:00, 61.01it/s]Computing norms:  97%|█████████▋| 1098/1129 [00:18<00:00, 60.97it/s]Computing norms:  98%|█████████▊| 1105/1129 [00:18<00:00, 60.90it/s]Computing norms:  98%|█████████▊| 1112/1129 [00:18<00:00, 60.68it/s]Computing norms:  99%|█████████▉| 1119/1129 [00:19<00:00, 60.66it/s]Computing norms: 100%|█████████▉| 1126/1129 [00:19<00:00, 60.65it/s]Computing norms: 100%|██████████| 1129/1129 [00:19<00:00, 58.58it/s]
Loading cached processed dataset at /scratch/lustre/home/auma4493/.cache/huggingface/datasets/imagefolder/glv2-next-final-f1222a0f34855ac2/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-2205f63149a7d495.arrow
torch.Size([1024])
Computing matrix:   0%|          | 0/1129 [00:00<?, ?it/s]Computing matrix:   5%|▌         | 60/1129 [00:00<00:01, 597.40it/s]Computing matrix:  11%|█         | 121/1129 [00:00<00:01, 601.52it/s]Computing matrix:  16%|█▌        | 182/1129 [00:00<00:01, 602.75it/s]Computing matrix:  22%|██▏       | 243/1129 [00:00<00:01, 600.65it/s]Computing matrix:  27%|██▋       | 304/1129 [00:00<00:01, 598.35it/s]Computing matrix:  32%|███▏      | 364/1129 [00:00<00:01, 588.92it/s]Computing matrix:  37%|███▋      | 423/1129 [00:00<00:01, 579.47it/s]Computing matrix:  43%|████▎     | 481/1129 [00:00<00:01, 574.14it/s]Computing matrix:  48%|████▊     | 539/1129 [00:00<00:01, 570.29it/s]Computing matrix:  53%|█████▎    | 597/1129 [00:01<00:00, 567.79it/s]Computing matrix:  58%|█████▊    | 654/1129 [00:01<00:00, 565.29it/s]Computing matrix:  63%|██████▎   | 711/1129 [00:01<00:00, 562.95it/s]Computing matrix:  68%|██████▊   | 768/1129 [00:01<00:00, 464.48it/s]Computing matrix:  73%|███████▎  | 824/1129 [00:01<00:00, 489.08it/s]Computing matrix:  78%|███████▊  | 881/1129 [00:01<00:00, 509.53it/s]Computing matrix:  83%|████████▎ | 938/1129 [00:01<00:00, 525.23it/s]Computing matrix:  88%|████████▊ | 995/1129 [00:01<00:00, 535.84it/s]Computing matrix:  93%|█████████▎| 1051/1129 [00:01<00:00, 542.13it/s]Computing matrix:  98%|█████████▊| 1108/1129 [00:02<00:00, 547.59it/s]Computing matrix: 100%|██████████| 1129/1129 [00:02<00:00, 551.63it/s]
[[0.8488135  0.82233873 0.84168831 ... 0.82889688 0.86320993 0.85890611]
 [0.86222873 0.78692781 0.83113618 ... 0.83728601 0.80345918 0.84829936]
 [0.85178278 0.80655788 0.86565689 ... 0.85359607 0.85188964 0.85638678]
 ...
 [0.86659273 0.84058671 0.86064623 ... 0.81338801 0.84333144 0.85836201]
 [0.84007169 0.82164882 0.85105171 ... 0.79759115 0.86994409 0.83629925]
 [0.85096318 0.82225384 0.85241509 ... 0.82203853 0.85758717 0.83751809]]
(1129, 10000)
[[ 0.00030588 -0.02616888 -0.0068193  ... -0.01961073  0.01470232
   0.0103985 ]
 [ 0.03322482 -0.0420761   0.00213227 ...  0.0082821  -0.02554473
   0.01929545]
 [ 0.0057282  -0.0394967   0.01960231 ...  0.00754149  0.00583506
   0.0103322 ]
 ...
 [ 0.01816275 -0.00784327  0.01221625 ... -0.03504197 -0.00509854
   0.00993203]
 [-0.0072901  -0.02571298  0.00368992 ... -0.04977064  0.0225823
  -0.01106254]
 [ 0.00726848 -0.02144087  0.00872038 ... -0.02165618  0.01389246
  -0.00617662]]
(1129, 10000)
Sorting indices
[  374324  8957386   456009 10551815  9412363  3503199 10332343 10406996
 10569127  7401815]
Sorted indices
Writing to csv
Sorting indices
[10551815  7401815  4702343  4640369 10406996  7171815   374324  3541815
  8957386 10332343]
Sorted indices
Writing to csv
